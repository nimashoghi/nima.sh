---
title: 'Neural network weight compression with nnw-bdi'
collection: publications
permalink: /publication/2020-Neural-network-weight-compression-with-nnw-bdi
excerpt: 'Developed NNW-BDI, a neural network weight compression scheme that reduces memory usage by up to 85% without sacrificing inference accuracy on an MNIST classification task.'
date: 2020
venue: 'Unknown'
paperurl: 'https://dl.acm.org/doi/abs/10.1145/3422575.3422805'
authors: 'Andrei Bersatti, <b>Nima Shoghi Ghalehshahi</b>, Hyesoon Kim'
citation: 'Andrei Bersatti, <b>Nima Shoghi Ghalehshahi</b>, Hyesoon Kim, Proceedings of the International Symposium on Memory Systems, 335-340, 2020'
full_citation: 'Andrei Bersatti, <b>Nima Shoghi Ghalehshahi</b>, Hyesoon Kim, Proceedings of the International Symposium on Memory Systems, 335-340, 2020'
---

This paper proposes NNW-BDI, a memory compression scheme for neural network weights that leverages techniques such as quantization, downscaling, randomized base selection, and base-delta-configuration adjustment. By compressing the weights of an MNIST classification network, NNW-BDI achieves up to 85% memory usage reduction without compromising inference accuracy, making it a promising solution for memory-constrained deep learning applications.

[Access paper here](https://dl.acm.org/doi/abs/10.1145/3422575.3422805){:target="_blank"}
