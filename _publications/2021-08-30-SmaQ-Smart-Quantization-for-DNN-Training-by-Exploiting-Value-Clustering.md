---
title: "SmaQ: Smart Quantization for DNN Training by Exploiting Value Clustering"
collection: publications
permalink: /publication/2021-08-30-SmaQ-Smart-Quantization-for-DNN-Training-by-Exploiting-Value-Clustering
excerpt: 'Introduces Smart Quantization (SmaQ), a quantization scheme that leverages the normal distribution properties of neural network data structures, leading to a memory usage reduction of up to 6.7x during training, with minimal impact on accuracy.'
date: 2021-08-30
venue: 'IEEE Computer Architecture Letters'
paperurl: 'https://doi.org/10.1109/LCA.2021.3108505'
citation: ' <b>Nima Shoghi</b>*,  Andrei Bersatti*,  Moinuddin Qureshi,  Hyesoon Kim, &quot;SmaQ: Smart Quantization for DNN Training by Exploiting Value Clustering.&quot; IEEE Computer Architecture Letters, 2021.'
---
Introduces Smart Quantization (SmaQ), a quantization scheme that leverages the normal distribution properties of neural network data structures, leading to a memory usage reduction of up to 6.7x during training, with minimal impact on accuracy.

[Access paper here](https://doi.org/10.1109/LCA.2021.3108505){:target="_blank"}
