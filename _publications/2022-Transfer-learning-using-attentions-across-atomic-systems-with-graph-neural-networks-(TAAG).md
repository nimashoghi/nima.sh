---
title: "Transfer learning using attentions across atomic systems with graph neural networks (TAAG)"
collection: publications
permalink: /publication/2022-Transfer-learning-using-attentions-across-atomic-systems-with-graph-neural-networks-(TAAG)
excerpt: 'Developed a transfer learning approach using Graph Neural Networks to generalize models across domains in molecular and catalyst discovery, reducing the need for large, domain-specific datasets.'
date: 2022
venue: 'The Journal of Chemical Physics'
paperurl: 'https://pubs.aip.org/aip/jcp/article/156/18/184702/2841241'
authors: 'Adeesh Kolluru, <b>Nima Shoghi</b>, Muhammed Shuaibi, Siddharth Goyal, Abhishek Das, C Lawrence Zitnick, Zachary Ulissi'
citation: 'Adeesh Kolluru, <b>Nima Shoghi</b>, Muhammed Shuaibi, Siddharth Goyal, Abhishek Das, C Lawrence Zitnick, Zachary Ulissi, The Journal of Chemical Physics 156 (18), 2022'
full_citation: 'Adeesh Kolluru, <b>Nima Shoghi</b>, Muhammed Shuaibi, Siddharth Goyal, Abhishek Das, C Lawrence Zitnick, Zachary Ulissi, The Journal of Chemical Physics 156 (18), 2022'
---

This research explores the use of transfer learning with Graph Neural Networks (GNNs) to generalize models across different domains in molecular and catalyst discovery. By pretraining a model on the Open Catalyst Dataset (OC20) and fine-tuning it on various datasets and tasks, including MD17, the CO adsorbate dataset, and OC20 itself, the study demonstrates that the initial layers of GNNs learn a more basic representation that can be effectively transferred to different domains, reducing the need for large, computationally expensive datasets in each domain.

[Access paper here](https://pubs.aip.org/aip/jcp/article/156/18/184702/2841241){:target="_blank"}
