---
title: "Legal Text Summarization Using Transformer Models"
collection: talks
type: "Talk"
permalink: /talks/2020-11-23-legal-text-summarization
venue: "CS 8803-DLT: Deep Learning for Text (Georgia Tech)"
date: 2020-11-23
location: "Atlanta, Georgia"
---

Develops a transformer-based encoder-decoder architecture for abstractive legal text summarization. Combines PEGASUS' (from Zhang et al. 2020) pre-training objective with Longformer's (from Beltagy et al. 2020) dilated attention mechanism to create a model that can handle extremely long input sequences to generate summaries of legal documents. Achieves state-of-the-art summarization performance on the BIGPATENT dataset.
